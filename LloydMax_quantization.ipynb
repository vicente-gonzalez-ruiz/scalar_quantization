{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lloyd-Max quantization\n",
    "\n",
    "* Minimizes the [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) of the quantization error, i.e., the expectation of the power of the quantization error, i.e. \n",
    "\\begin{equation}\n",
    " D = \\text{E}[(\\mathbf{x}-\\mathbf{y})^2],\n",
    "\\end{equation}\n",
    "where $D$ is the distortion generated by the quantizer, $\\mathbf{x}$ is the original signal, and $\\mathbf{y}$ is the reconstructed signal.\n",
    "* The PDF (in the analog case) or the histogram (digital signals) is required. The density of quantization bins is higher in those parts of the input dynamic range where the probability of the samples is also higher.\n",
    "* The quantizer must determine the decision levels, and the representation levels.\n",
    "* Inside of a bin (quantization step), the PDF/histogram is supposed to be constant. *For this reason, we select the representation level of each bin just in the middle point. This is the *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive quantization using the PDF\n",
    "In the continuous case, if $M$ is the number of bins, the distortion can be also expressed by\n",
    "\\begin{equation}\n",
    "D = \\sum_{k=1}^{M}\\int_{\\mathbf{b}_{k-1}}^{\\mathbf{b}_k}(\\mathbf{x}-\\mathbf{y}_k)^2P(x)dx,\n",
    "\\end{equation}\n",
    "where $\\mathbf{b}_k$ is the upper decision level of the $k$-th bin, $\\mathbf{y}_k$ is the representation level for the $k$-th bin, and $P(x)=f_\\mathbf{x}(x)$ is the probability of finding $x$ in the signal (considered as a random variable) $\\mathbf{x}$.\n",
    "\n",
    "To minimize $D$ we must solve\n",
    "\\begin{equation}\n",
    "\\frac{\\partial D}{\\partial \\mathbf{y}_k} = 0 = -\\sum_{k=1}^M\\int_{\\mathbf{b}_{k-1}}^{\\mathbf{b}_k}2(\\mathbf{x}-\\mathbf{y}_k)^2P(x)dx\n",
    "\\end{equation}\n",
    "which boilds down to\n",
    "\\begin{equation}\n",
    "= -\\int_{\\mathbf{b}_{k-1}}^{\\mathbf{b}_k}2(\\mathbf{x}-\\mathbf{y}_k)^2P(x)dx\n",
    "\\end{equation}\n",
    "because $\\mathbf{y}_k$ is only used in one of the bins. We continue\n",
    "\\begin{equation}\n",
    "= 2\\int_{\\mathbf{b}_{k-1}}^{\\mathbf{b}_k}\\mathbf{x}P(x)dx - 2\\mathbf{y}_k\\int_{\\mathbf{b}_{k-1}}^{\\mathbf{b}_k}P(x)dx.\n",
    "\\end{equation}\n",
    "Therefore:\n",
    "\\begin{equation}\n",
    "\\mathbf{y}_k = \\frac{\\int_{\\mathbf{b}_{k-1}}^{\\mathbf{b}_k}\\mathbf{x}P(x)dx}{\\int_{\\mathbf{b}_{k-1}}^{\\mathbf{b}_k}P(x)dx},\\tag{1}\n",
    "\\end{equation}\n",
    "i.e., the representation level $\\mathbf{y}_k$ for each bin is the centroid of the probability mass in that bin.\n",
    "\n",
    "Unfortunately, such equation express that, to find the representation levels $\\mathbf{y}_k$, we must determine first the decision levels $\\mathbf{b}_k$. For computing them, we can now minimize $D$ respect to $\\mathbf{b}_k$:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial D}{\\partial \\mathbf{b}_k} = 0,\n",
    "\\end{equation}\n",
    "which, supposing that the bins are small enough to consider that the probability of the values of $\\mathbf{x}$ is constant inside of each bin, ends up in that:\n",
    "\\begin{equation}\n",
    "\\mathbf{b}_k = \\frac{\\mathbf{y}_k+\\mathbf{y}_{k+1}}{2},\\tag{2}\n",
    "\\end{equation}\n",
    "a result quite logical under such supposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of the representation levels.\n",
    "\n",
    "Unfortunately, Equations (1) and (2) are mutually dependent. However, they can be used to compute $\\{\\mathbf{y}_k\\}_{k=1}^M$ and $\\{\\mathbf{b}_k\\}_{k=0}^M$ using the following iterative algorithm:\n",
    "\n",
    "0. Define $\\epsilon>0$.\n",
    "1. Initialize $\\mathbf{y}_k$ at random.\n",
    "2. Let $\\mathbf{c}=\\{\\mathbf{c}_k\\}_{k=0}^M=0$.\n",
    "2. While $ max(|\\mathbf{c}-\\mathbf{b}|) > \\epsilon$:\n",
    "    1. $\\mathbf{c}\\leftarrow \\mathbf{b}$.\n",
    "    1. Compute the boundary (decision) levels $\\mathbf{b}$ using Eq. (2).\n",
    "    2. Update the centroids (representation) levels $\\mathbf{y}$ using Eq. (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 64, 192, 256])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "uniform_filter1d([2.0, 8, 0, 4, 1, 9, 9.0, 0], size=2, origin=-1)\n",
    "uniform_filter1d([0, 128, 256], size=2, origin=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_boundaries(y):\n",
    "    b = uniform_filter1d(y, size=2, origin=-1)\n",
    "    print('y', y, 'b', b)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroids(b, P, M):\n",
    "    y = []\n",
    "    bin_size = P.size//M\n",
    "    for k in range(M):\n",
    "        b_k = k*bin_size\n",
    "        b_k_1 = (k+1)*bin_size\n",
    "        print(b_k, b_k_1)\n",
    "        mass = np.sum([i*P[i] for i in range(b_k, b_k_1)])\n",
    "        total_counts_in_bin = np.sum([P[i] for i in range(b_k, b_k_1)])\n",
    "        centroid = mass/total_counts_in_bin\n",
    "        y.append(centroid)\n",
    "    print('>y', np.array(y))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_levels(P, epsilon, max_iters, M, min_val, max_val):\n",
    "    initial_boundaries = np.linspace(min_val, max_val + 1, M + 1)\n",
    "    initial_centroids = 0.5 * (initial_boundaries[1:] + initial_boundaries[:-1])\n",
    "    initial_centroids = np.concatenate(([0], initial_centroids))\n",
    "    y = initial_centroids\n",
    "    print(y)\n",
    "    b = initial_boundaries\n",
    "    print(b)\n",
    "    c = np.zeros(b.size)\n",
    "    print(c)\n",
    "    i = 0\n",
    "    #print(M)\n",
    "    for i in range(max_iters):\n",
    "        print(i)\n",
    "        c[:] = b\n",
    "        b = compute_boundaries(y)\n",
    "        if (i>0) and (np.max(np.abs(c-b)) <= epsilon):\n",
    "            break\n",
    "        y = compute_centroids(b, P, M)\n",
    "    return b, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.  64. 192.]\n",
      "[  0. 128. 256.]\n",
      "[0. 0. 0.]\n",
      "0\n",
      "y [  0.  64. 192.] b [ 32. 128. 192.]\n",
      "0 1\n",
      "1 2\n",
      ">y [1 1]\n",
      "1\n",
      "y [1, 1] b [1 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [141]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m max_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m      6\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mcompute_levels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [140]\u001b[0m, in \u001b[0;36mcompute_levels\u001b[0;34m(P, epsilon, max_iters, M, min_val, max_val)\u001b[0m\n\u001b[1;32m     15\u001b[0m c[:] \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m     16\u001b[0m b \u001b[38;5;241m=\u001b[39m compute_boundaries(y)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mc\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mb\u001b[49m)) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m epsilon):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m compute_centroids(b, P, M)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (2,) "
     ]
    }
   ],
   "source": [
    "P = np.array([1, 1]) # Counts\n",
    "epsilon = 1e-5\n",
    "max_iters = 100\n",
    "min_val = 0\n",
    "max_val = 255\n",
    "M = 2\n",
    "compute_levels(P, epsilon, max_iters, M, min_val, max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://github.com/scikit-learn-contrib/scikit-learn-extra/archive/master.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = np.asarray([[1, 2], [1, 4], [1, 0],\n",
    "                [4, 2], [4, 4], [4, 0]])\n",
    "\n",
    "clusterer = KMeans(n_clusters=2, random_state=0)\n",
    "#clusterer.fit(X)\n",
    "Y = clusterer.fit_transform(X)\n",
    "print(\"labels =\", clusterer.labels_)\n",
    "clusterer.predict([[0,0], [4,4]])\n",
    "print(\"centers =\", clusterer.cluster_centers_)\n",
    "print(\"inertia =\", clusterer.inertia_)\n",
    "print(X, Y)\n",
    "#clusterer.get_feature_names_out()\n",
    "#clusterer.get_params()\n",
    "clusterer.score(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test K-medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def MSE(x, y):\n",
    "    d = x-y\n",
    "    dd = d*d\n",
    "    #print(x, y, x.shape, y.shape)\n",
    "    #return math.sqrt(np.sum(dd)/len(dd))\n",
    "    return np.sum(dd)/len(dd)\n",
    "\n",
    "def lagrangian(x, y):\n",
    "    return math.abs(x - y)\n",
    "\n",
    "X = np.asarray([[1, 2], [1, 4], [1, 0],\n",
    "                [4, 2], [4, 4], [4, 0]])\n",
    "\n",
    "#clusterer = KMedoids(n_clusters=2, random_state=0, metric=MSE).fit(X)\n",
    "clusterer = KMedoids(n_clusters=2, random_state=0).fit(X)\n",
    "print(\"labels =\", clusterer.labels_)\n",
    "clusterer.predict([[0,0], [4,4]])\n",
    "print(\"centers =\", clusterer.cluster_centers_)\n",
    "print(\"inertia =\", clusterer.inertia_)\n",
    "print(X, Y)\n",
    "#clusterer.get_feature_names_out()\n",
    "#clusterer.get_params()\n",
    "clusterer.score(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans computes centroids. KMedoids selects the inputs closest to the centroids. [KMedoids is related to the KMeans algorithm. While KMeans tries to minimize the within cluster sum-of-squares, KMedoids tries to minimize the sum of distances between each point and the medoid of its cluster. The medoid is a data point (unlike the centroid) which has the least total distance to the other members of its cluster.](https://scikit-learn-extra.readthedocs.io/en/stable/modules/cluster.html#k-medoids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Vector Quantization using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Robert Layton <robertlayton@gmail.com>\n",
    "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#          Mathieu Blondel <mathieu@mblondel.org>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from time import time\n",
    "\n",
    "n_colors = 64\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "china = np.array(china, dtype=np.float64) / 255\n",
    "\n",
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h, d = original_shape = tuple(china.shape)\n",
    "assert d == 3\n",
    "image_array = np.reshape(china, (w * h, d))\n",
    "\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000)\n",
    "kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0, n_samples=n_colors)\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "labels_random = pairwise_distances_argmin(codebook_random, image_array, axis=0)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    return codebook[labels].reshape(w, h, -1)\n",
    "\n",
    "\n",
    "# Display all results, alongside original image\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original image (96,615 colors)\")\n",
    "plt.imshow(china)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, K-Means)\")\n",
    "plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h))\n",
    "\n",
    "plt.figure(3)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, Random)\")\n",
    "plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Vector Quantization using K-medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Robert Layton <robertlayton@gmail.com>\n",
    "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#          Mathieu Blondel <mathieu@mblondel.org>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from time import time\n",
    "\n",
    "n_colors = 64\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "china = np.array(china, dtype=np.float64) / 255\n",
    "\n",
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h, d = original_shape = tuple(china.shape)\n",
    "assert d == 3\n",
    "image_array = np.reshape(china, (w * h, d))\n",
    "\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000)\n",
    "kmeans = KMedoids(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0, n_samples=n_colors)\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "labels_random = pairwise_distances_argmin(codebook_random, image_array, axis=0)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    return codebook[labels].reshape(w, h, -1)\n",
    "\n",
    "\n",
    "# Display all results, alongside original image\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original image (96,615 colors)\")\n",
    "plt.imshow(china)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, K-Medoids)\")\n",
    "plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h))\n",
    "\n",
    "plt.figure(3)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, Random)\")\n",
    "plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lloyd-Max quantization (of a gray-scaled image) using K-medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from time import time\n",
    "\n",
    "n_colors = 8\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "china = np.array(china, dtype=np.float64) #/ 255\n",
    "print(china.shape)\n",
    "china = (( china[...,0] + china[...,1] + china[...,0] ) / 3).astype(np.uint8)\n",
    "\n",
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h = original_shape = tuple(china.shape)\n",
    "image_array = np.reshape(china, w * h)\n",
    "\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000).reshape(-1, 1)\n",
    "kmeans = KMedoids(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array.reshape(-1, 1))\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "print(np.unique(labels))\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0, n_samples=n_colors)\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "#labels_random = pairwise_distances_argmin(codebook_random, image_array.reshape(-1, 1), axis=0)\n",
    "#print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    return codebook[labels].reshape(w, h, -1)\n",
    "\n",
    "\n",
    "# Display all results, alongside original image\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original image (96,615 colors)\")\n",
    "plt.imshow(china)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, K-Medoids)\")\n",
    "y = recreate_image(kmeans.cluster_centers_, labels, w, h)\n",
    "print(np.unique(y))\n",
    "plt.imshow(y)\n",
    "\n",
    "#plt.figure(3)\n",
    "#plt.clf()\n",
    "#plt.axis(\"off\")\n",
    "#plt.title(f\"Quantized image ({n_colors} colors, Random)\")\n",
    "#plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voronoi diagram of the hand-written digits using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "\n",
    "print(f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\")\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(\n",
    "            data,\n",
    "            estimator[-1].labels_,\n",
    "            metric=\"euclidean\",\n",
    "            sample_size=300,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\n",
    "        \"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
    "    )\n",
    "    print(formatter_result.format(*results))\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(82 * \"_\")\n",
    "print(\"init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\")\n",
    "\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_digits, n_init=4, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
    "\n",
    "kmeans = KMeans(init=\"random\", n_clusters=n_digits, n_init=4, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"random\", data=data, labels=labels)\n",
    "\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "kmeans = KMeans(init=pca.components_, n_clusters=n_digits, n_init=1)\n",
    "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=data, labels=labels)\n",
    "\n",
    "print(82 * \"_\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_digits, n_init=4)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Paired,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-means clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centroids are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voronoi diagram of the hand-written digits using K-medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "\n",
    "print(f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\")\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(\n",
    "            data,\n",
    "            estimator[-1].labels_,\n",
    "            metric=\"euclidean\",\n",
    "            sample_size=300,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\n",
    "        \"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
    "    )\n",
    "    print(formatter_result.format(*results))\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids as KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(82 * \"_\")\n",
    "print(\"init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\")\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_digits, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_digits, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"random\", data=data, labels=labels)\n",
    "\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "kmeans = KMeans(n_clusters=n_digits)\n",
    "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=data, labels=labels)\n",
    "\n",
    "print(82 * \"_\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(n_clusters=n_digits)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Paired,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-medoids clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centers are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a lagrangian $J =D+\\lambda R$ distance metric\n",
    "\n",
    "[The use of a data point to represent each clusterâ€™s center allows the use of any distance metric for clustering.](https://scikit-learn-extra.readthedocs.io/en/stable/modules/cluster.html#k-medoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from time import time\n",
    "import math\n",
    "\n",
    "def entropy(sequence_of_symbols):\n",
    "    assert sequence_of_symbols.ndim == 1\n",
    "    value, counts = np.unique(sequence_of_symbols, return_counts = True)\n",
    "    probs = counts / len(sequence_of_symbols)\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    _entropy = 0.\n",
    "    for i in probs:\n",
    "        _entropy -= i * math.log(i, 2)\n",
    "\n",
    "    return _entropy\n",
    "\n",
    "_lambda = 1.0 # This represents a slope and therefore, the dynamic ranges of the axis R and D are relevant\n",
    "\n",
    "def lagrangian(x, y):\n",
    "    distortion = abs(x - y)\n",
    "    return distortion\n",
    "    #rate = math.log(np.sum(abs(x-y)) + 1)\n",
    "    #return distortion + _lambda * rate\n",
    "\n",
    "def lagrangian(x, y):\n",
    "    d = x-y\n",
    "    dd = d*d\n",
    "    #print(x, y, x.shape, y.shape)\n",
    "    #return math.sqrt(np.sum(dd)/len(dd))\n",
    "    distortion = math.sqrt(np.sum(dd)/len(dd)) # dd is an array of 3 components (RGB)\n",
    "    rate = math.log(np.sum(abs(d)) + 1)\n",
    "    #print(np.sum(abs(x-y)), rate, x.shape, y.shape)\n",
    "    return distortion + _lambda * rate\n",
    "\n",
    "n_colors = 8\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "china = np.array(china, dtype=np.float64) / 255\n",
    "\n",
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h, d = original_shape = tuple(china.shape)\n",
    "assert d == 3\n",
    "image_array = np.reshape(china, (w * h, d))\n",
    "\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000)\n",
    "kmeans = KMedoids(n_clusters=n_colors, random_state=0, metric=lagrangian).fit(image_array_sample)\n",
    "#kmeans = KMedoids(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0, n_samples=n_colors)\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "labels_random = pairwise_distances_argmin(codebook_random, image_array, axis=0)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    return codebook[labels].reshape(w, h, -1)\n",
    "\n",
    "# Display all results, alongside original image\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original image (96,615 colors)\")\n",
    "plt.imshow(china)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, K-Medoids)\")\n",
    "plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h))\n",
    "\n",
    "plt.figure(3)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, Random)\")\n",
    "plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantizing a gray-scaled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos\" ]; then\n",
    "    echo \"\\\"$HOME/repos\\\" exists\"\n",
    "else\n",
    "    mkdir ~/repos\n",
    "    echo Created $HOME/repos\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/image_IO\" ]; then\n",
    "    cd $HOME/repos/image_IO\n",
    "    echo \"$HOME/repos/image_IO ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/image_IO.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/information_theory\" ]; then\n",
    "    cd $HOME/repos/image_IO\n",
    "    echo \"$HOME/repos/information_theory ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/information_theory.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -sf ~/repos/image_IO/image_1.py .\n",
    "!ln -sf ~/repos/image_IO/logging_config.py .\n",
    "!ln -sf ~/repos/information_theory/distortion.py .\n",
    "!ln -sf ~/repos/information_theory/information.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LloydMax_quantization as quantization\n",
    "import image_1 as gray_image\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.environ[\"HOME\"]\n",
    "fn = home + \"/repos/MRVC/images/lena_bw/\"\n",
    "#fn = home + \"/repos/MRVC/images/circle/\"\n",
    "#fn = home + \"/repos/MRVC/images/Hommer_bw/\"\n",
    "!ls -l {fn}\n",
    "\n",
    "# Quantizer selection\n",
    "#quantizer = quantization.LloydMax_Quantizer\n",
    "\n",
    "n_clusters = 4  # Number of bins\n",
    "N_tries = 4  # Number of times K-means is run (if the centroids are init at random)\n",
    "\n",
    "#N_bins = range(2, 128, 1)\n",
    "#N_bins = [2, 4, 8, 16, 32] #range(2, 128, 1)\n",
    "#N_bins = [8]\n",
    "\n",
    "gray_image.write = gray_image.debug_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gray_image.read(fn, 0)\n",
    "gray_image.show(img, fn + \"000.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_using_kmeans(img, N_bins=4):\n",
    "    flatten_img = img.reshape((-1, 1))  # flatten\n",
    "    clusterer = KMeans(n_clusters=N_bins)\n",
    "    clusterer.fit(flatten_img)\n",
    "    centroids = clusterer.cluster_centers_.squeeze().astype(np.uint8)  # Centroids\n",
    "    k = clusterer.labels_.astype(np.uint8)  # Labels of the centroids\n",
    "    y = centroids[k]\n",
    "    y.shape = img.shape\n",
    "    k.shape = img.shape\n",
    "    return k, y\n",
    "\n",
    "N_bins = 4\n",
    "\n",
    "k, y = quantize_using_kmeans(img, N_bins=N_bins)\n",
    "_distortion = distortion.RMSE(img, y)\n",
    "print(\"Used quantization indexes:\", np.unique(k))\n",
    "gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "print(f\"N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using K-medoids and (default) Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from time import time\n",
    "\n",
    "n_colors = 4\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = img # load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "china = np.array(china, dtype=np.float64) #/ 255\n",
    "print(china.shape)\n",
    "#china = (( china[...,0] + china[...,1] + china[...,0] ) / 3).astype(np.uint8)\n",
    "\n",
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h = original_shape = tuple(china.shape)\n",
    "image_array = np.reshape(china, w * h)\n",
    "\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000).reshape(-1, 1)\n",
    "kmeans = KMedoids(init=\"k-medoids++\", n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "#kmeans = KMedoids(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array.reshape(-1, 1))\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "print(np.unique(labels))\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0, n_samples=n_colors)\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "#labels_random = pairwise_distances_argmin(codebook_random, image_array.reshape(-1, 1), axis=0)\n",
    "#print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    return codebook[labels].reshape(w, h, -1)\n",
    "\n",
    "\n",
    "gray_image.show(china, \"Original image (96,615 colors)\")\n",
    "y = recreate_image(kmeans.cluster_centers_, labels, w, h)\n",
    "print(np.unique(y))\n",
    "gray_image.show(y, f\"Quantized image ({n_colors} colors, K-Medoids)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using K-medoids (again) and Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def quantize_using_kmedoids(img, N_bins=8):\n",
    "    flatten_img = img.reshape((-1, 1))  # flatten\n",
    "    clusterer = KMedoids(init=\"k-medoids++\", n_clusters=N_bins)\n",
    "    #clusterer = KMeans(n_clusters=N_bins)\n",
    "    image_array_sample = shuffle(flatten_img, random_state=0, n_samples=1_000)\n",
    "    clusterer.fit(image_array_sample)\n",
    "    k = clusterer.predict(flatten_img)\n",
    "    y = clusterer.cluster_centers_[k]\n",
    "    centroids = clusterer.cluster_centers_\n",
    "    k.shape = img.shape\n",
    "    y.shape = img.shape\n",
    "    return k, y\n",
    "    \n",
    "N_bins = 4\n",
    "\n",
    "k, y = quantize_using_kmedoids(img, N_bins=N_bins)\n",
    "_distortion = distortion.RMSE(img, y)\n",
    "print(\"Used quantization indexes:\", np.unique(k))\n",
    "gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "print(f\"N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort the quantization indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sort_indexes(clusterer):\n",
    "    centers = clusterer.cluster_centers_.squeeze() # Don't copy data (it's only a view)\n",
    "    idx = np.argsort(clusterer.cluster_centers_.sum(axis=1))\n",
    "    lut = np.zeros_like(idx)\n",
    "    lut[idx] = np.arange(centers.size)\n",
    "    argsort_lut = np.argsort(lut)\n",
    "    sorted_centroids = centers[argsort_lut]\n",
    "    sorted_labels = lut[clusterer.labels_]\n",
    "    centers[:] = sorted_centroids\n",
    "    clusterer.labels_ = sorted_labels\n",
    "    return clusterer\n",
    "\n",
    "def quantize_using_sorted_kmeans(img, N_bins=16):\n",
    "    flatten_img = img.reshape((-1, 1))  # flatten\n",
    "    clusterer = KMeans(n_clusters=N_bins)\n",
    "    clusterer.fit(flatten_img)\n",
    "    clusterer = sort_indexes(clusterer)\n",
    "    centroids = clusterer.cluster_centers_.squeeze().astype(np.uint8)  # Centroids\n",
    "    k = clusterer.labels_.astype(np.uint8)  # Labels of the centroids\n",
    "    y = centroids[k]\n",
    "    y.shape = img.shape\n",
    "    k.shape = img.shape\n",
    "    return k, y\n",
    "\n",
    "N_bins = 16\n",
    "\n",
    "k, y = quantize_using_kmeans(img, N_bins=N_bins)\n",
    "gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "k, y = quantize_using_sorted_kmeans(img, N_bins=N_bins)\n",
    "gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_using_sorted_kmedoids(img, N_bins=8, N_samples=0):\n",
    "    flatten_img = img.reshape((-1, 1))  # flatten\n",
    "    clusterer = KMedoids(init=\"k-medoids++\", n_clusters=N_bins)\n",
    "    if N_samples > 0:\n",
    "        image_array_sample = shuffle(flatten_img, random_state=0, n_samples=N_samples)\n",
    "    else:\n",
    "        image_array_sample = flatten_img\n",
    "    clusterer.fit(image_array_sample)\n",
    "    clusterer = sort_indexes(clusterer)\n",
    "    k = clusterer.predict(flatten_img)\n",
    "    y = clusterer.cluster_centers_[k]\n",
    "    centroids = clusterer.cluster_centers_\n",
    "    k.shape = img.shape\n",
    "    y.shape = img.shape\n",
    "    return k, y, clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins = 16\n",
    "\n",
    "k, y, _ = quantize_using_kmedoids(img, N_bins=N_bins, N_samples=1_000)\n",
    "gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "k, y, _ = quantize_using_sorted_kmedoids(img, N_bins=N_bins, N_samples=1_000)\n",
    "gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the lagrangian $J=D+\\lambda R$ distance metric (in K-medoids)\n",
    "K-means (at least the implementation of scikit-learn) can only use the Euclinean Distance :-/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "_lambda = 40.0 # The dynamic range of the related metrics must be considered\n",
    "\n",
    "_max_rate = 0.0\n",
    "_max_distortion = 0.0\n",
    "\n",
    "def lagrangian(x, y):\n",
    "    global _lambda, _max_rate, _max_distortion\n",
    "    d = x[0] - y[0]\n",
    "    #dd = d*d\n",
    "    #distortion = math.sqrt(dd/len(dd))\n",
    "    #distortion = dd\n",
    "    distortion = abs(d)\n",
    "    #distortion = np.linalg.norm(x-y)\n",
    "    #distortion = euclidean_distances(x.reshape(-1, 1), y.reshape(-1, 1))\n",
    "    if distortion > _max_distortion:\n",
    "        _max_distortion = distortion\n",
    "    rate = math.log(abs(d) + 1)\n",
    "    if rate > _max_rate:\n",
    "        _max_rate = rate\n",
    "    #print(_lambda, distortion)\n",
    "    return distortion\n",
    "    return distortion + _lambda * rate\n",
    "\n",
    "def quantize_using_sorted_kmedoids_with_metric(img, N_bins=8, N_samples=0, metric=lagrangian):\n",
    "    flatten_img = img.reshape((-1, 1))  # flatten\n",
    "    clusterer = KMedoids(init=\"k-medoids++\", n_clusters=N_bins, metric=metric)\n",
    "    if N_samples > 0:\n",
    "        image_array_sample = shuffle(flatten_img, random_state=0, n_samples=N_samples)\n",
    "    else:\n",
    "        image_array_sample = flatten_img\n",
    "    clusterer.fit(image_array_sample)\n",
    "    clusterer = sort_indexes(clusterer)\n",
    "    k = clusterer.predict(flatten_img)\n",
    "    y = clusterer.cluster_centers_[k]\n",
    "    centroids = clusterer.cluster_centers_\n",
    "    k.shape = img.shape\n",
    "    y.shape = img.shape\n",
    "    return k, y, clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_bins = 16\n",
    "k, y, _ = quantize_using_sorted_kmedoids_with_metric(img, N_bins=16, N_samples=1_000, metric=lagrangian)\n",
    "print(f\"max_distortion={_max_distortion}, max_rate={_max_rate}\")\n",
    "print(\"Used quantization indexes:\", np.unique(k))\n",
    "_distortion = distortion.RMSE(img, y)\n",
    "gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "print(f\"N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reduce image to guarantee that all pixels are used during the training\n",
    "\n",
    "def get_representation_levels(clusterer):\n",
    "    return clusterer.cluster_centers_.squeeze()\n",
    "\n",
    "def compute_rate(k, n, clusterer):\n",
    "    rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "    with open(\"/tmp/representation_levels.uint8\", mode=\"wb\") as f:\n",
    "        representation_levels = get_representation_levels(clusterer)\n",
    "        print(f\"representation_levels={representation_levels}\")\n",
    "        representation_levels.tofile(f)\n",
    "    rate += (os.path.getsize(\"/tmp/representation_levels.uint8\")*8/(k.shape[0]*k.shape[1]))\n",
    "    return rate\n",
    "\n",
    "import cv2\n",
    "reduced_img = cv2.resize(img, (64, 64))\n",
    "\n",
    "_lambda = 0\n",
    "\n",
    "k, y, _ = quantize_using_sorted_kmedoids_with_metric(resized_img, N_bins=16, N_samples=0, metric=lagrangian)\n",
    "print(f\"max_distortion={_max_distortion}, max_rate={_max_rate}\")\n",
    "print(\"Used quantization indexes:\", np.unique(k))\n",
    "print(f\"lambda={_lambda:>4}, N_bins={N_bins:>3}, distortion={distortion.RMSE(reduced_img, y):>6.4f},\\\n",
    "      entropy={entropy(k.flatten()):>6.4}, rate={compute_rate(k, N_bins, _):>6.4}\")\n",
    "\n",
    "_lambda = 40\n",
    "\n",
    "k, y, _ = quantize_using_sorted_kmedoids_with_metric(resized_img, N_bins=16, N_samples=0, metric=lagrangian)\n",
    "print(f\"max_distortion={_max_distortion}, max_rate={_max_rate}\")\n",
    "print(\"Used quantization indexes:\", np.unique(k))\n",
    "print(f\"lambda={_lambda:>4}, N_bins={N_bins:>3}, distortion={distortion.RMSE(reduced_img, y):>6.4f},\\\n",
    "      entropy={entropy(k.flatten()):>6.4}, rate={compute_rate(k, N_bins, _):>6.4}\")\n",
    "\n",
    "_lambda = 400\n",
    "\n",
    "k, y, _ = quantize_using_sorted_kmedoids_with_metric(resized_img, N_bins=16, N_samples=0, metric=lagrangian)\n",
    "print(f\"max_distortion={_max_distortion}, max_rate={_max_rate}\")\n",
    "print(\"Used quantization indexes:\", np.unique(k))\n",
    "print(f\"lambda={_lambda:>4}, N_bins={N_bins:>3}, distortion={distortion.RMSE(reduced_img, y):>6.4f},\\\n",
    "      entropy={entropy(k.flatten()):>6.4}, rate={compute_rate(k, N_bins, _):>6.4}\")\n",
    "\n",
    "k, y, _ = quantize_using_sorted_kmedoids_with_metric(resized_img, N_bins=8, N_samples=0, metric=lagrangian)\n",
    "print(f\"max_distortion={_max_distortion}, max_rate={_max_rate}\")\n",
    "print(\"Used quantization indexes:\", np.unique(k))\n",
    "print(f\"lambda={_lambda:>4}, N_bins={N_bins:>3}, distortion={distortion.RMSE(reduced_img, y):>6.4f},\\\n",
    "      entropy={entropy(k.flatten()):>6.4}, rate={compute_rate(k, N_bins, _):>6.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some previous results\n",
    "\n",
    "    max_distortion=206.0, max_rate=5.332718793265369\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    [ 44.  54.  72.  85.  97. 105. 115. 126. 135. 145. 155. 163. 178. 194.\n",
    "     205. 215.]\n",
    "    lambda=   0, N_bins= 16, distortion=3.3491,      entropy= 3.927, rate=  3.67\n",
    "    max_distortion=206.0, max_rate=5.332718793265369\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    [ 47.  55.  75.  93. 102. 108. 117. 127. 134. 144. 150. 157. 165. 178.\n",
    "     194. 208.]\n",
    "    lambda=  40, N_bins= 16, distortion=3.6668,      entropy= 3.963, rate= 3.758\n",
    "    max_distortion=206.0, max_rate=5.332718793265369\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    [ 45.  52.  61.  75.  93. 100. 108. 121. 129. 143. 150. 156. 163. 177.\n",
    "     194. 208.]\n",
    "    lambda= 400, N_bins= 16, distortion=3.5672,      entropy= 3.971, rate= 3.719\n",
    "    max_distortion=206.0, max_rate=5.332718793265369\n",
    "    Used quantization indexes: [0 1 2 3 4 5 6 7]\n",
    "    [ 49.  75.  99. 116. 129. 145. 158. 195.]\n",
    "    lambda= 400, N_bins= 16, distortion=7.3055,      entropy= 2.962, rate= 2.766\n",
    "\n",
    "    max_distortion=209.0, max_rate=5.3471075307174685\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    _lambda=0, N_bins= 16, rate=3.6796875 bits/pixel, distortion=3.31710, entropy=3.917608170461749\n",
    "    max_distortion=209.0, max_rate=5.3471075307174685\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    _lambda=40, N_bins= 16, rate=3.666015625 bits/pixel, distortion=3.53522, entropy=3.9250249477707864\n",
    "    max_distortion=209.0, max_rate=5.3471075307174685\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    _lambda=4000, N_bins= 16, rate=3.736328125 bits/pixel, distortion=3.52021, entropy=3.966581293271344\n",
    "    max_distortion=209.0, max_rate=5.3471075307174685\n",
    "    Used quantization indexes: [0 1 2 3 4 5 6 7]\n",
    "    _lambda=4000, N_bins=  8, rate=2.755859375 bits/pixel, distortion=7.39723, entropy=2.96753198946939\n",
    "\n",
    "    max_distortion=205.0, max_rate=5.327876168789581\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    _lambda=0, N_bins= 16, rate=3.787109375 bits/pixel, distortion=3.36253, entropy=3.95136060621473\n",
    "    max_distortion=205.0, max_rate=5.327876168789581\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    _lambda=40, N_bins= 16, rate=3.73046875 bits/pixel, distortion=3.75159, entropy=3.9008265965939115\n",
    "    max_distortion=205.0, max_rate=5.327876168789581\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    _lambda=4000, N_bins= 16, rate=3.755859375 bits/pixel, distortion=3.59670, entropy=3.9622656631482345\n",
    "    max_distortion=205.0, max_rate=5.327876168789581\n",
    "    Used quantization indexes: [0 1 2 3 4 5 6 7]\n",
    "    _lambda=4000, N_bins=  8, rate=2.689453125 bits/pixel, distortion=7.46460, entropy=2.9417908530659456\n",
    "\n",
    "    max_distortion=205.0, max_rate=5.327876168789581\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    _lambda=0, N_bins= 16, rate=3.66015625 bits/pixel, distortion=3.44023, entropy=3.8858449825573533\n",
    "    max_distortion=205.0, max_rate=5.327876168789581\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    _lambda=40, N_bins= 16, rate=3.685546875 bits/pixel, distortion=3.58201, entropy=3.9070442785597437\n",
    "    max_distortion=205.0, max_rate=5.327876168789581\n",
    "    Used quantization indexes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
    "    _lambda=4000, N_bins= 16, rate=3.728515625 bits/pixel, distortion=3.60342, entropy=3.9285071340839655\n",
    "    max_distortion=205.0, max_rate=5.327876168789581\n",
    "    Used quantization indexes: [0 1 2 3 4 5 6 7]\n",
    "    _lambda=4000, N_bins=  8, rate=2.796875 bits/pixel, distortion=7.04590, entropy=2.9820561942650836"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\lambda=0$, and we minimize $J=D+\\lambda R$, we are minimizing the distortion, only. If $\\lambda=40$ (that must be selecting a point in the \"middle\" of the RD curve), the distortion should increase and the rate should decrease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the Euclidean distance is the same than RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_lambda = 0\n",
    "k1, y1, clusterer1 = quantize_using_sorted_kmedoids_with_metric(resized_img, N_bins=16, metric=lagrangian)\n",
    "print(f\"lambda={_lambda:>4}, N_bins={N_bins:>3}, distortion={distortion.RMSE(reduced_img, y1):>6.4f},\\\n",
    "      entropy={entropy(k1.flatten()):>6.4}, rate={compute_rate(k1, N_bins, clusterer1):>6.4}\")\n",
    "k2, y2, clusterer2 = quantize_using_sorted_kmedoids(resized_img, N_bins=16)\n",
    "print(f\"lambda={_lambda:>4}, N_bins={N_bins:>3}, distortion={distortion.RMSE(reduced_img, y2):>6.4f},\\\n",
    "      entropy={entropy(k2.flatten()):>6.4}, rate={compute_rate(k2, N_bins, clusterer2):>6.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [ 47.  57.  72.  84.  97. 105. 116. 126. 134. 144. 152. 161. 176. 191.\n",
    "     203. 212.]\n",
    "    lambda=   0, N_bins= 16, distortion=3.3937,      entropy= 3.934, rate= 3.717\n",
    "    [ 45.  54.  68.  80.  94. 103. 114. 122. 129. 141. 151. 160. 172. 181.\n",
    "     195. 209.]\n",
    "    lambda=   0, N_bins= 16, distortion=3.4245,      entropy= 3.935, rate= 3.732\n",
    "\n",
    "\n",
    "    [ 43.  50.  59.  73.  85.  96. 104. 114. 123. 131. 143. 152. 161. 177.\n",
    "     195. 210.]\n",
    "    lambda=   0, N_bins= 16, distortion=3.3585,      entropy= 3.956, rate= 3.699\n",
    "    [ 47.  57.  72.  84.  96. 105. 118. 129. 139. 146. 155. 163. 178. 194.\n",
    "     207. 217.]\n",
    "    lambda=   0, N_bins= 16, distortion=3.3752,      entropy= 3.909, rate= 3.676\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using (again) a lagrangian $J =D+\\lambda R$ distance metric with the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def quantize_using_kmedoids(img, N_bins=4, _lambda=1.0):\n",
    "    def lagrangian(x, y):\n",
    "        d = x-y\n",
    "        dd = d*d\n",
    "        distortion = math.sqrt(dd/len(dd))\n",
    "        rate = math.log(abs(d) + 1)\n",
    "        return distortion + _lambda * rate\n",
    "\n",
    "    flatten_img = img.reshape((-1, 1))  # flatten\n",
    "    clusterer = KMedoids(init=\"k-medoids++\", n_clusters=N_bins, metric=lagrangian)\n",
    "    #clusterer = KMeans(n_clusters=N_bins)\n",
    "    image_array_sample = shuffle(flatten_img, random_state=0, n_samples=1_000)\n",
    "    print(\"Input pixels:\", np.unique(image_array_sample))\n",
    "    clusterer.fit(image_array_sample)\n",
    "    k = clusterer.predict(flatten_img)\n",
    "    y = clusterer.cluster_centers_[k]\n",
    "    centroids = clusterer.cluster_centers_\n",
    "    #print(centroids)\n",
    "    k.shape = img.shape\n",
    "    y.shape = img.shape\n",
    "    print(\"Used quantization indexes:\", np.unique(k))\n",
    "    _distortion = distortion.RMSE(img, y)\n",
    "    gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "    gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "    print(f\"N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")\n",
    "quantize_using_kmedoids(img, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check is Euclidean distance is the same than RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_using_kmedoids(img, 4, _lambda = 0)\n",
    "def quantize_using_kmedoids(img, N_bins=8):\n",
    "    flatten_img = img.reshape((-1, 1))  # flatten\n",
    "    clusterer = KMedoids(init=\"k-medoids++\", n_clusters=N_bins)\n",
    "    #clusterer = KMeans(n_clusters=N_bins)\n",
    "    image_array_sample = shuffle(flatten_img, random_state=0, n_samples=1_000)\n",
    "    print(\"Input pixels:\", np.unique(image_array_sample))\n",
    "    clusterer.fit(image_array_sample)\n",
    "    k = clusterer.predict(flatten_img)\n",
    "    y = clusterer.cluster_centers_[k]\n",
    "    centroids = clusterer.cluster_centers_\n",
    "    #print(centroids)\n",
    "    k.shape = img.shape\n",
    "    y.shape = img.shape\n",
    "    print(\"Used quantization indexes:\", np.unique(k))\n",
    "    _distortion = distortion.RMSE(img, y)\n",
    "    gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "    gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "    print(f\"N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")\n",
    "quantize_using_kmedoids(img, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RD_curve_sorted_labels(img, N_bins):\n",
    "    points = []\n",
    "    for n in N_bins:\n",
    "        Q_step = 256//n\n",
    "        Q = quantizer(img, Q_step=Q_step)\n",
    "        y, k = Q.quan_dequan(img)\n",
    "        print(\"Quantization indexes:\", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        with open(\"/tmp/representation_levels.uint8\", mode=\"wb\") as f:\n",
    "            Q.get_representation_levels().tofile(f)\n",
    "        rate += (os.path.getsize(\"/tmp/representation_levels.uint8\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "        #    np.save(file=f, arr=Q.get_representation_levels())\n",
    "        #rate += (os.path.getsize(\"/tmp/representation_levels.npy.gz\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #_distortion = distortion.RMSE(img, y)\n",
    "        _distortion = distortion.RMSE(img, np.round(y).astype(np.uint8))\n",
    "        gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={n})\")\n",
    "        #if n<16:\n",
    "        #    plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "        #    plt.show()\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"N_bins={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "RD_points_sorted_labels = RD_curve_sorted_labels(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_using_kmeans(img, N_bins=8):\n",
    "    Q_step = 256//N_bins\n",
    "    Q = quantizer(img, Q_step)\n",
    "    y, k = Q.quan_dequan(img)\n",
    "    print(\"Used quantization indexes:\", np.unique(k))\n",
    "    _distortion = distortion.RMSE(img, y)\n",
    "    gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "    gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "    print(f\"N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")\n",
    "quantize_using_kmeans(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_using_kmedoids(img, N_bins=8):\n",
    "    Q_step = 256//N_bins\n",
    "    Q = quantizer(img, Q_step, use_medoid=True)\n",
    "    y, k = Q.quan_dequan(img)\n",
    "    print(\"Used quantization indexes:\", np.unique(k))\n",
    "    _distortion = distortion.RMSE(img, y)\n",
    "    gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "    gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "    print(f\"N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")\n",
    "quantize_using_kmedoids(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using (again) a lagrangian $J =D+\\lambda R$ distance metric with the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_using_kmedoids(img, N_bins=8, _lambda=1.0):\n",
    "    def lagrangian(x, y):\n",
    "        d = x-y\n",
    "        dd = d*d\n",
    "        distortion = math.sqrt(dd/len(dd))\n",
    "        rate = math.log(abs(d) + 1)\n",
    "        return distortion + _lambda * rate\n",
    "    \n",
    "    Q_step = 256//N_bins\n",
    "    Q = quantizer(img, Q_step, use_medoid=True, metric=lagrangian)\n",
    "    y, k = Q.quan_dequan(img)\n",
    "    print(\"Used quantization indexes:\", np.unique(k))\n",
    "    _distortion = distortion.RMSE(img, y)\n",
    "    gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "    #gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "    print(f\"N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")\n",
    "\n",
    "quantize_using_kmedoids(img, 8, 0)\n",
    "quantize_using_kmedoids(img, 8, 1)\n",
    "quantize_using_kmedoids(img, 8, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_using_kmedoids(img, N_bins=8, _lambda=1.0):\n",
    "    def lagrangian(x, y):\n",
    "        d = x-y\n",
    "        dd = d*d\n",
    "        distortion = math.sqrt(dd/len(dd))\n",
    "        rate = math.log(abs(d) + 1)\n",
    "        return distortion + _lambda * rate\n",
    "\n",
    "    Q_step = 256//N_bins\n",
    "    Q = quantizer(img, Q_step, use_medoid=True, metric=lagrangian)\n",
    "    y, k = Q.quan_dequan(img)\n",
    "    print(\"Used quantization indexes:\", np.unique(k))\n",
    "    _distortion = distortion.RMSE(img, y)\n",
    "    print(f\"lambda={_lambda:>6.1f}, N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")\n",
    "    return y\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "def f(x, y):\n",
    "    return np.sin(x) + np.cos(y)\n",
    "\n",
    "x = np.linspace(0, 2 * np.pi, 120)\n",
    "y = np.linspace(0, 2 * np.pi, 100).reshape(-1, 1)\n",
    "\n",
    "# ims is a list of lists, each row is a list of artists to draw in the\n",
    "# current frame; here we are just animating one artist, the image, in\n",
    "# each frame\n",
    "ims = []\n",
    "for _lambda in [0, 0.5, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0]:\n",
    "    if _lambda == 0:\n",
    "        ax.imshow(img, cmap=\"gray\")  # show an initial one first\n",
    "        t = ax.annotate(\"original\", (10,20))\n",
    "    else:\n",
    "        y = quantize_using_kmedoids(img, 8, _lambda)\n",
    "        _distortion = distortion.RMSE(img, y)\n",
    "        t = ax.annotate(f\"lambda={_lambda} distortion={_distortion}\", (10,20))\n",
    "    im = ax.imshow(y, animated=True, cmap=\"gray\")\n",
    "    ims.append([im, t])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "# To save the animation, use e.g.\n",
    "#\n",
    "# ani.save(\"movie.mp4\")\n",
    "#\n",
    "# or\n",
    "#\n",
    "# writer = animation.FFMpegWriter(\n",
    "#     fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "# ani.save(\"movie.mp4\", writer=writer)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test if $\\lambda=0$ in $J=D+\\lambda R$ equivals to using the Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_using_kmedoids(img, N_bins=8, _lambda=1.0):\n",
    "    def lagrangian(x, y):\n",
    "        d = x-y\n",
    "        dd = d*d\n",
    "        distortion = math.sqrt(dd/len(dd))\n",
    "        rate = math.log(abs(d) + 1)\n",
    "        return distortion + _lambda * rate\n",
    "    \n",
    "    Q_step = 256//N_bins\n",
    "    Q = quantizer(img, Q_step, use_medoid=True, metric=lagrangian)\n",
    "    y, k = Q.quan_dequan(img)\n",
    "    print(\"Used quantization indexes:\", np.unique(k))\n",
    "    _distortion = distortion.RMSE(img, y)\n",
    "    gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "    #gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "    print(f\"N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")\n",
    "\n",
    "quantize_using_kmedoids(img, 8, 0)\n",
    "\n",
    "def quantize_using_kmedoids(img, N_bins=8):\n",
    "    \n",
    "    Q_step = 256//N_bins\n",
    "    Q = quantizer(img, Q_step, use_medoid=True, metric=lagrangian)\n",
    "    y, k = Q.quan_dequan(img)\n",
    "    print(\"Used quantization indexes:\", np.unique(k))\n",
    "    _distortion = distortion.RMSE(img, y)\n",
    "    gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={N_bins})\")\n",
    "    #gray_image.show(y, f\"Reconstruction (N_bins={N_bins})\")\n",
    "    print(f\"N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")\n",
    "\n",
    "quantize_using_kmedoids(img, 8)\n",
    "quantize_using_kmedoids(img, 8, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 128)   # start,stop,step\n",
    "y = np.log(x + 1)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def quantize_using_kmedoids(img, information_of_symbols, N_bins=8, _lambda=1.0):\n",
    "    def lagrangian(x, y):\n",
    "        d = x-y\n",
    "        dd = d*d\n",
    "        distortion = math.sqrt(dd/len(dd))\n",
    "        rate = information_of_symbols[abs(d)] # We suppose that the histogram of <d> shows a symmetry centered at 0\n",
    "        return distortion + _lambda * rate\n",
    "\n",
    "    Q_step = 256//N_bins\n",
    "    Q = quantizer(img, Q_step, use_medoid=True, metric=lagrangian)\n",
    "    y, k = Q.quan_dequan(img)\n",
    "    print(\"Used quantization indexes:\", np.unique(k))\n",
    "    _distortion = distortion.RMSE(img, y)\n",
    "    print(f\"lambda={_lambda:>6.1f}, N_bins={N_bins:>3}, distortion={_distortion:>6.1f}\")\n",
    "    return y\n",
    "\n",
    "def symbols_information(sequence_of_symbols):\n",
    "    assert sequence_of_symbols.ndim == 1\n",
    "    value, counts = np.unique(sequence_of_symbols, return_counts = True)\n",
    "    probs = counts / len(sequence_of_symbols)\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    information_of_symbols = []\n",
    "    for i in probs:\n",
    "        information_of_symbols.append(-math.log(i, 2))\n",
    "\n",
    "    return information_of_symbols\n",
    "\n",
    "_lambda = 1.0\n",
    "\n",
    "information_of_symbols = symbols_information(img.flatten())\n",
    "print(information_of_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(information_of_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(information_of_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram, bin_edges = np.histogram(img, bins=256, range=(0, 255))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Histogram\")\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.plot(bin_edges[0:-1], histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

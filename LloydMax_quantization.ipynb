{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lloyd-Max quantization\n",
    "\n",
    "* Minimizes the [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) of the quantization error, i.e., the expectation of the power of the quantization error, i.e. \n",
    "\\begin{equation}\n",
    " D = \\text{E}[(\\mathbf{x}-\\mathbf{y})^2],\n",
    "\\end{equation}\n",
    "where $D$ is the distortion generated by the quantizer, $\\mathbf{x}$ is the original signal, and $\\mathbf{y}$ is the reconstructed signal.\n",
    "* The PDF (in the analog case) or the histogram (digital signals) is required. The density of quantization bins is higher in those parts of the input dynamic range where the probability of the samples is also higher.\n",
    "* The quantizer must determine the decision levels, and the representation levels.\n",
    "* Inside of a bin (quantization step), the PDF/histogram is supposed to be constant. *For this reason, we select the representation level of each bin just in the middle point. This is the *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive quantization using the PDF\n",
    "In the continuous case, if $M$ is the number of bins, the distortion can be expressed by\n",
    "\\begin{equation}\n",
    "D = \\sum_{i=1}^{M}\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}(\\mathbf{x}-\\mathbf{c}_i)^2P(x)dx,\n",
    "\\end{equation}\n",
    "where $\\mathbf{b}_i$ is the upper decision level of the $i$-th bin, $\\mathbf{c}_i$ is the representation level for the $i$-th bin, and $P(x)=f_\\mathbf{x}(x)$ is the probability of finding $x$ in the signal (considered as a random variable) $\\mathbf{x}$.\n",
    "\n",
    "To minimize $D$ we must solve\n",
    "\\begin{equation}\n",
    "\\frac{\\partial D}{\\partial \\mathbf{c}_i} = 0 = -\\sum_{i=1}^M\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}2(\\mathbf{x}-\\mathbf{c}_i)^2P(x)dx\n",
    "\\end{equation}\n",
    "which boilds down to\n",
    "\\begin{equation}\n",
    "= -\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}2(\\mathbf{x}-\\mathbf{c}_i)^2P(x)dx\n",
    "\\end{equation}\n",
    "because $\\mathbf{c}_i$ is only used in one of the bins. We continue\n",
    "\\begin{equation}\n",
    "= 2\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}\\mathbf{x}P(x)dx - 2\\mathbf{c}_i\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}P(x)dx.\n",
    "\\end{equation}\n",
    "Therefore:\n",
    "\\begin{equation}\n",
    "\\mathbf{c}_i = \\frac{\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}\\mathbf{x}P(x)dx}{\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}P(x)dx},\\tag{1}\n",
    "\\end{equation}\n",
    "i.e., the representation level $\\mathbf{c}_i$ for each bin is the centroid of the probability mass in that bin. Notice that, in order to avoid a division by 0, at least one one sample must belong to each bin.\n",
    "\n",
    "Unfortunately, such equation express that, to find the representation levels $\\mathbf{c}_i$, we must determine first the decision levels $\\mathbf{b}_i$. For computing them, we can now minimize $D$ respect to $\\mathbf{b}_i$:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial D}{\\partial \\mathbf{b}_i} = 0,\n",
    "\\end{equation}\n",
    "which, supposing that the bins are small enough to consider that the probability of the values of $\\mathbf{x}$ is constant inside of each bin, ends up in that:\n",
    "\\begin{equation}\n",
    "\\mathbf{b}_i = \\frac{\\mathbf{c}_i+\\mathbf{c}_{i+1}}{2},\\tag{2}\n",
    "\\end{equation}\n",
    "a result quite logical under such supposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of the representation levels.\n",
    "\n",
    "Unfortunately, Equations (1) and (2) are mutually dependent. However, they can be used to compute $\\{\\mathbf{y}_k\\}_{k=1}^M$ and $\\{\\mathbf{b}_k\\}_{k=0}^M$ using the following iterative algorithm:\n",
    "\n",
    "0. Define $\\epsilon>0$.\n",
    "1. Initialize $\\mathbf{c}_k$ /* centroids */ at random.\n",
    "2. Let $\\mathbf{previous\\_b}=\\{\\mathbf{previous\\_d}_k\\}_{k=0}^M=0$ /* boundaries */.\n",
    "2. While $ max(|\\mathbf{previous\\_b}-\\mathbf{b}|) > \\epsilon$:\n",
    "    1. $\\mathbf{previous\\_b}\\leftarrow \\mathbf{b}$.\n",
    "    1. Compute the boundary (decision) levels $\\mathbf{b}$ using Eq. (2).\n",
    "    2. Update the centroids (representation levels) $\\mathbf{c}$ using Eq. (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "uniform_filter1d([2.0, 8, 0, 4, 1, 9, 9.0, 0], size=2, origin=-1)\n",
    "uniform_filter1d([0, 128, 256], size=2, origin=-1)[:-1]\n",
    "print(uniform_filter1d([64, 192], size=2, origin=-1)[:-1])\n",
    "print(uniform_filter1d([64, 192], size=2, mode=\"nearest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import center_of_mass\n",
    "x = np.array([1,2,3,4,5])\n",
    "center_of_mass(x)\n",
    "\n",
    "x = np.array([1,1,1,1,1])\n",
    "center_of_mass(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_boundaries(c):\n",
    "    b = uniform_filter1d(c, size=2, origin=-1)[:-1]\n",
    "    b = np.concatenate(([0],b,[256]))\n",
    "    #print('y', y, 'b', b)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroids(b, P, M):\n",
    "    c = []\n",
    "    bin_size = P.size//M\n",
    "    print(\"bin_size\", bin_size)\n",
    "    for i in range(M):\n",
    "        b_i = i*bin_size\n",
    "        b_i_1 = (i+1)*bin_size\n",
    "        print(\"b_i\", b_i, \"b_i_1\", b_i_1)\n",
    "        # See from scipy.ndimage import center_of_mass\n",
    "        mass = np.sum([j*P[j] for j in range(b_i, b_i_1)])\n",
    "        total_counts_in_bin = np.sum([P[j] for j in range(b_i, b_i_1)])\n",
    "        #if total_counts_in_bin > 0:\n",
    "        centroid = mass/total_counts_in_bin\n",
    "        #print(\"1\", centroid, b_i, b_i_1)\n",
    "        #centroid = center_of_mass(b[i+1]*P[b_i:b_i_1])[0]\n",
    "        #print(\"2\", centroid, b[i])\n",
    "        #else:\n",
    "        #    centroid = mass/bin_size\n",
    "        c.append(centroid)\n",
    "    #print('>c', np.array(c))\n",
    "    return np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_levels(P, epsilon, max_iters, M, min_val, max_val):\n",
    "    initial_boundaries = np.linspace(min_val, max_val + 1, M + 1)\n",
    "    initial_centroids = 0.5 * (initial_boundaries[1:] + initial_boundaries[:-1])\n",
    "    #initial_centroids = np.concatenate(([0], initial_centroids))\n",
    "    c = initial_centroids\n",
    "    #print('c', c)\n",
    "    b = initial_boundaries\n",
    "    print('b', b)\n",
    "    prev_b = np.zeros(b.size)\n",
    "    print('prev_b', prev_b)\n",
    "    #print(M)\n",
    "    for j in range(max_iters):\n",
    "        print('j', j)\n",
    "        prev_b[:] = b\n",
    "        b = compute_boundaries(c)\n",
    "        max_abs_error = np.max(np.abs(prev_b-b))\n",
    "        print(\"max_abs_error\", max_abs_error)\n",
    "        if (j>0) and (max_abs_error <= epsilon):\n",
    "            break\n",
    "        c = compute_centroids(b, P, M)\n",
    "    return b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.ones(256) # Counts for uniform distribution\n",
    "#P = np.random.randint(low=0, high=2000, size=256)\n",
    "epsilon = 1e-5\n",
    "max_iters = 100\n",
    "min_val = 0\n",
    "max_val = 255\n",
    "M = 2\n",
    "compute_levels(P, epsilon, max_iters, M, min_val, max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos\" ]; then\n",
    "    echo \"\\\"$HOME/repos\\\" exists\"\n",
    "else\n",
    "    mkdir ~/repos\n",
    "    echo Created $HOME/repos\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/image_IO\" ]; then\n",
    "    cd $HOME/repos/image_IO\n",
    "    echo \"$HOME/repos/image_IO ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/image_IO.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/information_theory\" ]; then\n",
    "    cd $HOME/repos/image_IO\n",
    "    echo \"$HOME/repos/information_theory ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/information_theory.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -sf ~/repos/image_IO/image_1.py .\n",
    "!ln -sf ~/repos/image_IO/logging_config.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_1 as gray_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.environ[\"HOME\"]\n",
    "fn = home + \"/repos/MRVC/images/lena_bw/\"\n",
    "#fn = home + \"/repos/MRVC/images/circle/\"\n",
    "#fn = home + \"/repos/MRVC/images/Hommer_bw/\"\n",
    "!ls -l {fn}\n",
    "\n",
    "# Quantizer selection\n",
    "#quantizer = quantization.LloydMax_Quantizer\n",
    "\n",
    "n_clusters = 4  # Number of bins\n",
    "N_tries = 4  # Number of times K-means is run (if the centroids are init at random)\n",
    "\n",
    "#N_bins = range(2, 128, 1)\n",
    "#N_bins = [2, 4, 8, 16, 32] #range(2, 128, 1)\n",
    "#N_bins = [8]\n",
    "\n",
    "gray_image.write = gray_image.debug_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gray_image.read(fn, 0)\n",
    "gray_image.show(img, fn + \"000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram, bin_edges = np.histogram(img, bins=256, range=(0, 256))\n",
    "histogram[histogram==0] = 1\n",
    "print(histogram, bin_edges)\n",
    "print(len(histogram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    #plt.rcParams['text.usetex'] = True\n",
    "    #plt.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}'] #for \\text command\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Histogram\")\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.plot(bin_edges[0:-1], histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = histogram\n",
    "epsilon = 1e-5\n",
    "max_iters = 100\n",
    "min_val = 0\n",
    "max_val = 255\n",
    "M = 128\n",
    "boundaries, centroids = compute_levels(P, epsilon, max_iters, M, min_val, max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(centroids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.searchsorted(boundaries, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.unique(indexes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show_normalized(indexes, fn + \"000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_img = centroids[indexes].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show(quantized_img, fn + \"000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LloydMax_quantization as quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = quantization.LloydMax_Quantizer\n",
    "Q = quantizer(Q_step=4, counts=histogram)\n",
    "print(\"decision_levels =\", Q.get_decision_levels())\n",
    "print(\"representation_levels =\", Q.get_representation_levels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_img, indexes = Q.encode_and_decode(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.show_normalized(indexes, fn + \"000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, y, xlabel='', ylabel='', title=''):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.grid()\n",
    "    ax.xaxis.set_label_text(xlabel)\n",
    "    ax.yaxis.set_label_text(ylabel)\n",
    "    ax.plot(x, y)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 255, 500) # Input samples\n",
    "y, k = Q.encode_and_decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = \"Input Sample\"\n",
    "ylabel = \"Reconstructed Sample\"\n",
    "title = f\"Lloyd-Max Quantizer ({fn}, $\\Delta={QSS}$)\"\n",
    "\n",
    "ax1 = plt.subplot()\n",
    "counts, bins = np.histogram(img, range(257))\n",
    "l1 = ax1.bar(bins[:-1] - 0.5, counts, width=1, edgecolor='none')\n",
    "ax2 = ax1.twinx()\n",
    "l2, = ax2.plot(x, y, color='m')\n",
    "\n",
    "plt.legend([l1, l2], [\"Histogram\", \"Lloyd-Max Quantizer\"])\n",
    "ax1.yaxis.set_label_text(\"Pixel Value Count\")\n",
    "ax2.yaxis.set_label_text(\"Reconstructed Value\")\n",
    "ax1.xaxis.set_label_text(\"Input Sample\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

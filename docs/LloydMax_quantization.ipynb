{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/vicente-gonzalez-ruiz/scalar_quantization/blob/master/docs/LloydMax_quantization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=notebook)](https://colab.research.google.com/github/vicente-gonzalez-ruiz/scalar_quantization/blob/master/docs/LloydMax_quantization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lloyd-Max quantization\n",
    "\n",
    "* Minimizes the [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) of the quantization error, i.e., the expectation of the power of the quantization error\n",
    "\\begin{equation}\n",
    " D = \\text{E}[(\\mathbf{x}-\\mathbf{y})^2],\n",
    "\\end{equation}\n",
    "where $D$ is the distortion generated by the quantizer, $\\mathbf{x}$ is the original signal, and $\\mathbf{y}$ is the reconstructed signal.\n",
    "* The [PDF](https://en.wikipedia.org/wiki/Probability_density_function) (in the analog case) or the [histogram](https://en.wikipedia.org/wiki/Histogram) (digital signals) is required. The density of quantization bins is higher in those parts of the input dynamic range where the probability of the samples is also higher.\n",
    "* The quantizer must determine the decision levels, and the representation levels, which are the centroid of each bin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive quantization using the PDF\n",
    "In the continuous case, if $M$ is the number of bins, the distortion can be expressed by\n",
    "\\begin{equation}\n",
    "D = \\sum_{i=1}^{M}\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}(\\mathbf{x}-\\mathbf{c}_i)^2P(x)dx,\n",
    "\\end{equation}\n",
    "where $\\mathbf{b}_i$ is the upper decision level of the $i$-th bin, $\\mathbf{c}_i$ is the representation level for the $i$-th bin, and $P(x)=f_\\mathbf{x}(x)$ is the probability of finding $x$ in the signal (considered as a random variable) $\\mathbf{x}$.\n",
    "\n",
    "To minimize $D$ we must solve\n",
    "\\begin{equation}\n",
    "\\frac{\\partial D}{\\partial \\mathbf{c}_i} = 0 = -\\sum_{i=1}^M\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}2(\\mathbf{x}-\\mathbf{c}_i)^2P(x)dx\n",
    "\\end{equation}\n",
    "which boilds down to\n",
    "\\begin{equation}\n",
    "= -\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}2(\\mathbf{x}-\\mathbf{c}_i)^2P(x)dx\n",
    "\\end{equation}\n",
    "because $\\mathbf{c}_i$ is only used in one of the bins. We continue and therefore\n",
    "\\begin{equation}\n",
    "= 2\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}\\mathbf{x}P(x)dx - 2\\mathbf{c}_i\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}P(x)dx.\n",
    "\\end{equation}\n",
    "Solving,\n",
    "\\begin{equation}\n",
    "\\mathbf{c}_i = \\frac{\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}\\mathbf{x}P(x)dx}{\\int_{\\mathbf{b}_{i-1}}^{\\mathbf{b}_i}P(x)dx},\\tag{1}\n",
    "\\end{equation}\n",
    "i.e., the representation level $\\mathbf{c}_i$ for each bin is the centroid of the probability mass in that bin. Notice that, in order to avoid a division by 0, at least one one sample must belong to each bin.\n",
    "\n",
    "Unfortunately, such equation express that, to find the representation levels $\\mathbf{c}_i$, we must determine first the decision levels $\\mathbf{b}_i$. For computing them, we can now minimize $D$ respect to $\\mathbf{b}_i$:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial D}{\\partial \\mathbf{b}_i} = 0,\n",
    "\\end{equation}\n",
    "which, supposing that the bins are small enough to consider that the probability of the values of $\\mathbf{x}$ is constant inside of each bin, ends up in that:\n",
    "\\begin{equation}\n",
    "\\mathbf{b}_i = \\frac{\\mathbf{c}_i+\\mathbf{c}_{i+1}}{2},\\tag{2}\n",
    "\\end{equation}\n",
    "a result quite logical under such supposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of the representation levels.\n",
    "\n",
    "Unfortunately, Equations (1) and (2) are mutually dependent. However, they can be used to compute $\\{\\mathbf{y}_k\\}_{k=1}^M$ and $\\{\\mathbf{b}_k\\}_{k=0}^M$ using the following iterative algorithm:\n",
    "\n",
    "1. Initialize $\\mathbf{c}_k$ /* centroids */ at random.\n",
    "2. Let $\\mathbf{previous\\_b}=\\{\\mathbf{previous\\_b}_k\\}_{k=0}^M=0$ /* boundaries */.\n",
    "2. While not reached some stopping criteria:\n",
    "    1. $\\mathbf{previous\\_b}\\leftarrow \\mathbf{b}$.\n",
    "    1. Compute the boundary (decision) levels $\\mathbf{b}$ using Eq. (2).\n",
    "    2. Update the centroids (representation levels) $\\mathbf{c}$ using Eq. (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "# from scipy.ndimage import center_of_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_boundaries(c):\n",
    "    b = uniform_filter1d(c, size=2, origin=-1)[:-1]\n",
    "    b = np.concatenate(([0],b,[256]))\n",
    "    print('b', b)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroids(b, P, M):\n",
    "    ended = False\n",
    "    c = []\n",
    "    bin_size = P.size//M\n",
    "    print(\"bin_size\", bin_size)\n",
    "    for i in range(len(b) - 1):\n",
    "        b_i = int(round(b[i]))    #i*bin_size\n",
    "        b_i_1 = int(round(b[i+1]))#(i+1)*bin_size\n",
    "        if b_i == b_i_1:\n",
    "            ended = True\n",
    "            break\n",
    "        print(\"b_i\", b_i, \"b_i_1\", b_i_1)\n",
    "        # See from scipy.ndimage import center_of_mass\n",
    "        mass = np.sum([j*P[j] for j in range(b_i, b_i_1)])\n",
    "        total_counts_in_bin = np.sum([P[j] for j in range(b_i, b_i_1)])\n",
    "        assert total_counts_in_bin > 0, f\"bin [{b_i}, {b_i_1}] is not used (b={b})\"\n",
    "        centroid = mass/total_counts_in_bin\n",
    "        c.append(centroid)\n",
    "    return np.array(c), ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_levels(P, M, max_iters):\n",
    "    total_count = np.sum(P)\n",
    "    bin_count = total_count/M\n",
    "    initial_boundaries = [0.]\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    for p in P:\n",
    "        acc += p\n",
    "        counter += 1\n",
    "        if acc > bin_count:\n",
    "            initial_boundaries.append(float(counter))\n",
    "            acc = 0\n",
    "    initial_boundaries.append(256.)\n",
    "    initial_boundaries = np.array(initial_boundaries)\n",
    "    initial_centroids = 0.5 * (initial_boundaries[1:] + initial_boundaries[:-1])\n",
    "    print(\"initial_centroids\", initial_centroids, len(initial_centroids))\n",
    "    c = initial_centroids\n",
    "    b = initial_boundaries\n",
    "    prev_b = np.zeros(b.size)\n",
    "    for j in range(max_iters):\n",
    "        prev_b[:] = b\n",
    "        b = compute_boundaries(c)\n",
    "        max_abs_error = np.max(np.abs(prev_b-b))\n",
    "        print(\"max_abs_error\", max_abs_error)\n",
    "        prev_c = c\n",
    "        c, ended = compute_centroids(b, P, M)\n",
    "        if ended:\n",
    "            break\n",
    "    return b, prev_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.ones(256) # Counts for uniform distribution\n",
    "#P = np.random.randint(low=0, high=2000, size=256) # Counts for random distribution\n",
    "max_iters = 100\n",
    "M = 2\n",
    "boundaries, centroids = compute_levels(P, M, max_iters)\n",
    "print('boundaries', boundaries)\n",
    "print('centroids', centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize an array that follows an uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the data to quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 255, 256)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    #plt.rcParams['text.usetex'] = True\n",
    "    #plt.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}'] #for \\text command\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"x\")\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the histogram(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_x, bin_edges_x = np.histogram(x, bins=256, range=(0, 256))\n",
    "histogram_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Histogram(x)\")\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.plot(bin_edges_x[0:-1], histogram_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.searchsorted(boundaries, x, side=\"right\") - 1\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"k\")\n",
    "plt.xlabel(\"index\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.plot(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = centroids[k]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"y\")\n",
    "plt.xlabel(\"decoded\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from skimage import io\n",
    "    from skimage.color import rgb2gray\n",
    "except:\n",
    "    !pip install scikit-image\n",
    "    from skimage import io\n",
    "    from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"http://www.hpca.ual.es/~vruiz/images/lena.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(fn)\n",
    "img = (rgb2gray(img)*256).astype(np.uint8)\n",
    "plt.figure()\n",
    "plt.title(fn)\n",
    "io.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_img, bin_edges_img = np.histogram(img, bins=256, range=(0, 256))\n",
    "histogram_img[histogram_img==0] = 1\n",
    "print(\"histogram\", histogram_img)\n",
    "print(\"\\bin_edges\", bin_edges_img)\n",
    "print(len(histogram_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Histogram\")\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.plot(bin_edges_img[0:-1], histogram_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = histogram_img\n",
    "M = 128\n",
    "boundaries_img, centroids_img = compute_levels(P, M, max_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boundaries_img, len(boundaries_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centroids_img, len(centroids_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(histogram_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_img = np.searchsorted(boundaries_img, img) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes_img.shape)\n",
    "print(np.min(indexes_img))\n",
    "print(np.max(indexes_img))\n",
    "print(np.unique(indexes_img))\n",
    "print(len(np.unique(indexes_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('k')\n",
    "io.imshow(indexes_img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_img = centroids_img[indexes_img]#.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoded_img.min(), decoded_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"decoded\")\n",
    "io.imshow(decoded_img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 255, 256) # Input samples\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_x = np.searchsorted(boundaries_img, x) - 1\n",
    "indexes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_x = centroids_img[indexes_x]#.astype(np.uint8)\n",
    "decoded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = \"Input Sample\"\n",
    "ylabel = \"Reconstructed Sample\"\n",
    "title = f\"Lloyd-Max Quantizer ({fn}, $\\M={M}$)\"\n",
    "\n",
    "ax1 = plt.subplot()\n",
    "counts, bins = np.histogram(img, range(256))\n",
    "l1 = ax1.bar(bins[:-1] - 0.5, counts, width=1, edgecolor='none')\n",
    "ax2 = ax1.twinx()\n",
    "l2, = ax2.plot(x[1:], decoded_x[1:], color='m')\n",
    "\n",
    "plt.title(\"Histogram VS Quantization Function\")\n",
    "plt.legend([l1, l2], [\"Histogram\", \"Lloyd-Max Quantizer\"])\n",
    "ax1.yaxis.set_label_text(\"Pixel Value Count\")\n",
    "ax2.yaxis.set_label_text(\"Reconstructed Value\")\n",
    "ax1.xaxis.set_label_text(\"Input Sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in those input ranges where the number of gray-tones are more frequent, the resolution of the quantizer is increased, and the representation levels are placed where the MSE is minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from scalar_quantization.LloydMax_quantization import LloydMax_Quantizer as Quantizer                          \n",
    "    from scalar_quantization.LloydMax_quantization import name as quantizer_name\n",
    "except:\n",
    "    !pip install \"scalar_quantization @ git+https://github.com/vicente-gonzalez-ruiz/scalar_quantization\"\n",
    "    from scalar_quantization.LloydMax_quantization import LloydMax_Quantizer as Quantizer\n",
    "    from scalar_quantization.LloydMax_quantization import name as quantizer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_step = 128\n",
    "Q = Quantizer(Q_step=Q_step, counts=histogram_img)\n",
    "print(\"decision_levels =\", Q.get_decision_levels())\n",
    "print(\"representation_levels =\", Q.get_representation_levels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantized_img, indexes = Q.encode_and_decode(img.flatten())\n",
    "quantized_img, indexes = Q.encode_and_decode(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gray_image.show_normalized(indexes.reshape(img.shape), fn + \"000.png\")\n",
    "#gray_image.show(quantized_img, \"y\")\n",
    "#gray_image.show(quantized_img, \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('y')\n",
    "io.imshow(quantized_img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_step = 32\n",
    "Q = Quantizer(Q_step=Q_step, counts=histogram_img)\n",
    "print(\"decision_levels =\", Q.get_decision_levels())\n",
    "print(\"representation_levels =\", Q.get_representation_levels())\n",
    "quantized_img, indexes = Q.encode_and_decode(img)\n",
    "plt.figure()\n",
    "plt.title('y')\n",
    "io.imshow(quantized_img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_step = 2\n",
    "Q = Quantizer(Q_step=Q_step, counts=histogram_img)\n",
    "print(\"decision_levels =\", Q.get_decision_levels())\n",
    "print(\"representation_levels =\", Q.get_representation_levels())\n",
    "quantized_img, indexes = Q.encode_and_decode(img)\n",
    "plt.figure()\n",
    "plt.title('y')\n",
    "io.imshow(quantized_img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
